<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Post-mortemâœ¨ğŸ’€: How To Handle Big Files With RabbitMQğŸ‡ and PostgreSQLğŸ˜? | ğŸˆNatalie PerretğŸ«</title><meta name=keywords content="coding,work,interview"><meta name=description content="I love it when a plan comes together, but there are times it just doesn'tğŸª–."><meta name=author content><link rel=canonical href=https://natalie-o-perret.github.io/posts/2-2021-02-15-post-mortem-how-to-handle-big-files-with-rabbitmq-and-postgresql/><link crossorigin=anonymous href=/assets/css/stylesheet.min.b4a650b31c3b670c7bf466f3f04d1c7a95456b48505e68397c36c858b059da18.css integrity="sha256-tKZQsxw7Zwx79Gbz8E0cepVFa0hQXmg5fDbIWLBZ2hg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.2840b7fccd34145847db71a290569594bdbdb00047097f75d6495d162f5d7dff.js integrity="sha256-KEC3/M00FFhH23GikFaVlL29sABHCX911kldFi9dff8=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://natalie-o-perret.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://natalie-o-perret.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://natalie-o-perret.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://natalie-o-perret.github.io/apple-touch-icon.png><link rel=mask-icon href=https://natalie-o-perret.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Post-mortemâœ¨ğŸ’€: How To Handle Big Files With RabbitMQğŸ‡ and PostgreSQLğŸ˜?"><meta property="og:description" content="I love it when a plan comes together, but there are times it just doesn'tğŸª–."><meta property="og:type" content="article"><meta property="og:url" content="https://natalie-o-perret.github.io/posts/2-2021-02-15-post-mortem-how-to-handle-big-files-with-rabbitmq-and-postgresql/"><meta property="og:image" content="https://natalie-o-perret.github.io/images/gallery/2-2021-02-15-post-mortem-how-to-handle-big-files-with-rabbitmq-and-postgresql.jpg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-02-15T00:00:00+00:00"><meta property="article:modified_time" content="2021-02-15T00:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://natalie-o-perret.github.io/images/gallery/2-2021-02-15-post-mortem-how-to-handle-big-files-with-rabbitmq-and-postgresql.jpg"><meta name=twitter:title content="Post-mortemâœ¨ğŸ’€: How To Handle Big Files With RabbitMQğŸ‡ and PostgreSQLğŸ˜?"><meta name=twitter:description content="I love it when a plan comes together, but there are times it just doesn'tğŸª–."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://natalie-o-perret.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Post-mortemâœ¨ğŸ’€: How To Handle Big Files With RabbitMQğŸ‡ and PostgreSQLğŸ˜?","item":"https://natalie-o-perret.github.io/posts/2-2021-02-15-post-mortem-how-to-handle-big-files-with-rabbitmq-and-postgresql/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Post-mortemâœ¨ğŸ’€: How To Handle Big Files With RabbitMQğŸ‡ and PostgreSQLğŸ˜?","name":"Post-mortemâœ¨ğŸ’€: How To Handle Big Files With RabbitMQğŸ‡ and PostgreSQLğŸ˜?","description":"I love it when a plan comes together, but there are times it just doesn'tğŸª–.","keywords":["coding","work","interview"],"articleBody":"TL;DR â±ï¸ Long story short: 90%-out-of-the-blue chance that you just donâ€™t.\nIf you want more details about our story, then feel free to keep reading ğŸ‘“â¬‡ï¸.\nContext ğŸ–¼ï¸ A not-so-long-whileğŸ¦– agoğŸ¦• we had some alertsğŸ“ŸğŸ”” in our dedicated Slack ChannelğŸ’¬, triggered every now and then when a particular HangFire job was running:\n\"XXXXXXX DataLoader\" \"Production\" Error 2021-01-22 09:04 SpanId: \"xxxxxxxxxxxxx\" TraceId: \"xxxxxxxxxxxxx\" An unhandled exception occurred during the Hangfire job. Depth 0: System.AggregateException One or more errors occurred. (The operation has timed out.) Depth 1: System.TimeoutException The operation has timed out. At first, it was just a RabbitMQ thingyâ€¦ ğŸ‡ We then looked at our logs in KibanağŸ”, just to find out that there was actually an issue related to opening a RabbitMQ ChannelğŸ“¡:\nSystem.AggregateException One or more errors occurred. (The operation has timed out.) System.AggregateException: One or more errors occurred. (The operation has timed out.) --- System.TimeoutException: The operation has timed out. at RabbitMQ.Util.BlockingCell`1.WaitForValue(TimeSpan timeout) at RabbitMQ.Client.Impl.SimpleBlockingRpcContinuation.GetReply(TimeSpan timeout) at RabbitMQ.Client.Impl.ModelBase.ModelRpc(MethodBase method, ContentHeaderBase header, Byte[] body) at RabbitMQ.Client.Framing.Impl.Model._Private_ChannelOpen(String outOfBand) at RabbitMQ.Client.Framing.Impl.AutorecoveringConnection.CreateNonRecoveringModel() at RabbitMQ.Client.Framing.Impl.AutorecoveringConnection.CreateModel() [...] GooglingğŸ” aroundğŸ—ºï¸ didnâ€™t yield too many results at first, even if we found a bunch of (remotely) related issues on GitHubğŸ—ƒï¸:\n Time out exception on CreateModel in high volume scenario Using blocking publisher confirms with concurrent publishers Opening a channel inside a consumer interface callback times out waiting for continuation Timeout exception when trying to declare a queue (or exchange)  The Process âš™ï¸ Since there wasnâ€™t really a clear solution out of our prelimenary investigations, it was time to step back and see a slightly bigger picture about what the Hangfire job was doing overall:\n Request data from an APIğŸ’± Create groupsğŸ˜ï¸ based on some predicates Process the groups as commands in our PostgreSQL-basedğŸ˜ event store and then persistğŸ’¾ the newly decided/generated events PublishğŸ’¾ the events to RabbitMQğŸ‡  Oopsieâ€¦ seems like PostgreSQL ğŸ˜ is also failing! Truth to be toldğŸ§™â€â™€ï¸, there was also an issue occuring during the PostgreSQL persistence step as wellğŸ”:\nAn unhandled exception has occurred while executing the request. System.AggregateException: One or more errors occurred. (One or more errors occurred. (One or more errors occurred. (One or m ore errors occurred. (Exception while reading from stream)))) --- System.AggregateException: One or more errors occurred. (One or more errors occurred. (One or more errors occurred. (Ex ception while reading from stream))) --- System.AggregateException: One or more errors occurred. (One or more errors occurred. (Exception while reading from str eam)) --- System.AggregateException: One or more errors occurred. (Exception while reading from stream) --- Npgsql.NpgsqlException (0x80004005): Exception while reading from stream --- System.TimeoutException: Timeout during reading attempt RabbitMQğŸ‡ + Multithreading ğŸ§µ: A Love Story ğŸ’â€¦ NopeâŒ Another pesty little detailğŸ¦ , is that we tried to speed upâ© the RabbitMQ publishing process using PSeq and the PublishBatch API of the official RabbitMQ .NET client.\nThe thing you see, is that during our first iterationğŸ§—â€â™€ï¸ when implementing this service (and more generally-speaking when we were implementing the RabbitMQ support in our codebase), we already have experienced issues while experimenting with IModel in a concurrent fashion (i.e. multithreading) which obviously turned out to be a rather infamously well-known concernğŸ‘©â€ğŸ¤. So much, that there is in fact, a section of the official RabbitMQ dedicated about it:\n As a rule of thumb, IModel instance usage by more than one thread simultaneously should be avoided. Application code should maintain a clear notion of thread ownership for IModel instances.\n So here is the catch, we were not using EasyNetQ, or any abstraction layer on top of the official RabbitMQ .NET client, and something like the management of a single instance of IModel per thread was suboptimal to put it mildly, i.e. we were creating a new IModel instance everytime we needed to send a batch of messages wich at some point started to create a bottleneck (i.e. several instantiations per threadğŸ§µ).\nTbf, it was already a source of strugglesğŸ‹ï¸â€â™€ï¸, actually weâ€™ve noticed that our implementation was much slowerğŸŒ at sending messages than the EasyNetQ abstractionâ€¦ and one of the reasons was the way EasyNetQ achieved this one single IModel instance per thread policy, in essence the number of IModel instances is kept to a bare minimum. Some of the important building blocks are listed below:\n AsyncLock RabbitAdvancedBus PersistentChannel  Anyway, my colleague Yazide Boujlil managed to come up with the explanations below:\n For each client connection, we have a socket which is shared between the threads via a .NET Channel that acts as some sort of buffer. Several threads can write to it, but only a single thread will read what is there and therefore will eventually write data to the relevant socket.\nThe RMQ channels (IModel) are merely the byproductsğŸ¤ of the RMQ connection. Each message which passes through the socket contains the ID of the channel to which it is attached. To declare a channel you need a small blocking RPC upon which we have experienced our annoying timeoutsâ°.\nNow it turns out that the server can actually put connectionsğŸ”Œ that publish too quicklyğŸš… (compared to consumers) in flow control mode, i.e. aka on hold, like putting them on iceğŸ§Š, and block and unblock the connection to limit the flow of messagesğŸš§.\nNow what is happening, in my opinion, is that we ended up in a situation where we overload both the server and the client. The server goes into a flow control mode which does not allow the client to empty its buffer and therefore any new channel creation is blocked until the cache is cleared. As there is a timeout on the channel creation, eventually the shit hit the fan.\n We naively thought that using the good oldğŸ‘µ ThreadLocal was the simplest and easiest way to go to keep this one IModel instance per thread.\nAnyhoo, we kept investigatingğŸ”¬ to tackle this IModel issue in a concurrent context, and found a few articles (two of the links below were written by Mike Hadlow, the author of the EasyNetQ library):\n Very high latency for GC when using (loads of) ThreadLocal EasyNetQ: A Breaking Change, IPublishChannel How Do I Detect When a Client Thread Exits?  The point made by MikeğŸ‘‡:\n Initially Iâ€™d hoped to hide channels from EasyNetQ usersğŸ™ˆ. With subscriptions this makes sense - after the client creates a subscription, EasyNetQ looks after the channel and the subscription consuming thread. But publishing turned out to be more complex. Channels cannot be shared between threads, so EasyNetQ initially used a ThreadLocal channel for all publish callsâ˜ï¸. A new thread meant a new channelğŸŒ„.\nThis problem manifested itself with a nasty operational bug we suffered. We had a service which woke up on a timer, created some threads, and published messages on them. Although the threads ended, the channels didnâ€™t closeğŸ“­, and each timer intervalğŸ•°ï¸ added another few open channels.\n So okâ€¦ it seems that just relying on the vanilla edition of ThreadLocalğŸ¨ might not do, mostly cause this concurrency primitive does not handle the exiting thread scenario.\nFair enough, we kept googlingğŸ” and found these two little gemsğŸ’ drafted by AyendeğŸ‘¨â€ğŸ«:\n The slow slowdown of large systems The design and implementation of a better ThreadLocal  As well this libraryğŸ“š:\n UnmanagedThreadUtils  We started to draft our own implementation of ThreadLocal supporting the thread exiting scenario when carrying a IDisposable resource, a bit like what is described in this SO answer.\nâ€œIt worksâ€¦ but not on my machine!â€ (the usual Natalie ğŸ’»ğŸ™‹â€â™€ï¸) At this stage, we were fairly confident that we had a working solution to solve our initial problem. But spoiler alert: we did not and we were once again prooved all wrongğŸ™…â€â™€ï¸, once again. While we were reviewing our new solution before shipping it to our integration environment, we quickly realized that there was something off when using a sizable amount of data. In fact, I still kept having timeoutsâ° while my other colleagues did not. We were all testing using the same codebase and the same Docker configurationğŸ‹â€¦ so by all accounts we were supposed to get the same results andâ€¦ and we were all wondering â€œHow is that even possible?â€\nâ€œHey Capâ€™, looks like itâ€™s related to your hardwareâ€ ğŸ’½ğŸ‘©â€âœˆï¸ Fair enough, yes, my laptopğŸ’» is infamously slow when compared to the machinesğŸ–¥ï¸ of my teammates.\nIt didnâ€™t take us too long to realize that given different pieces of hardware (RAM, CPU) accessed (i.e. limited) either thru a VM or a Docker ContainerğŸ³ mean they still can have vastly different performances. Itâ€™s then easy to understand that the underlying hardware powering this or that bit of infra is likely to improve or worsen the capability to support a bigger number of concurrent writers. If your hardware falls short, itâ€™s very likely that youâ€™re going to have a lock-bottleneck at some point.\nBetter Parallelism, an attempt â†—ï¸ğŸ§µ One way to tackle the overall concurrency per layer of infra was to adjust using the TPL DataFlow - TPL. It goes without saying that different environment had different infra constraints.\nâ€œBtw, if itâ€™s really just a timeout problem, canâ€™t you just increase the value of the so-called timeout?â€ â†—ï¸â³ Yes and we did on multiple occasions. Also one more thing, it wasnâ€™t just about a Hangfire job, we also have an admin api so-to-speak to restart the job we mentioned early on and it was expected to run within 5 minutes (or as fast as possible). The thing is that it wasnâ€™t just a timeout thing, or even just about parallelism and what we already listed above, causeâ€¦\nBig File (You Are Beautiful!) ğŸŒˆğŸ’¾ â€¦ basically here is the deal, we needed to juggled with all these intertwined bits of parameters:\n PostgreSQL: Timeout (we want that as fast as possible)â° RabbitMQ: Timeout (same as above)â° RabbitMQ: Single IModel per Thread policyğŸ‘®â€â™€ï¸ Maximum degree of parallelism per â€œIO layerâ€ ğŸ”€ The respective bits of hardware / VM / Docker containers supporting a given service and relevant bits of infrastructure dependenciesğŸ’ª  The overall problem looked like a Gordian knotğŸ§¶ until we realized that we could bypass it altogether with a different approachâ€¦ when we started to a have closer look atâ€¦ wellâ€¦ the filesğŸ’¾ and more precisely, their average size.\nIn retrospect, persisting â€œrelatively big filesâ€ 100MB either to a JSONB columnğŸ§® or to RabbitMQ (tho for the RabbitMQ part there were first split based on some business conditions) wasnâ€™t really the best option available out thereâ€¦ performance-wiseğŸ¢.\nSolution ğŸŒŸ Given all the information above, it became crystal clearğŸ”® that the main hiccup was to persist files where they were not really supposed to be persistedâ€¦ so we decided to useâ€¦\n(â€œaâ€ Corporate[i.e. on-premise]) S3 â˜ï¸ Our first and original â€œsin\"ğŸ› was purely architecturalğŸ“. Removing the file persistenceğŸ’¾ from PostgreSQL and RabbitMQ â€œdutiesâ€ and hence keeping just a reference(i.e. ID) to the file in the S3 bucketğŸ’¿ did alleviate a lot the IO burden by several orders of magnitude.\nWhat we have done is essentially delegatingâï¸ the infra burden to another service that is good at handling file persistence and â€œvoila\"ğŸ·ğŸ¥–.\nNote: I didnâ€™t mention it when I first drafted this article, but if you consider that several instances of the same service are running simulatenously and given that the even store is a very central building block in our architecture it makes sense to NOT burden it with long concurrent writes.\nEasyNetQ ğŸ°âŒ¨ï¸ This issue (and the investigations we did around this issue) made us realize another problem. When we started to use RabbitMQ in our project we thought we would need a certain granularity hence the decision to pick the rather low-level RabbitMQ .NET official clientâ€¦\nWe had this premise, because in our past experience with Entity FrameworkğŸ§°, the overly complex abstraction made us litterally miserableğŸ˜¿ and we were spending (i.e. wasting?) more time fightingâš”ï¸ the framework than benefiting from it (i.e. you deliver less business-value).\nBut keep in mind that the opposite is also true (i.e. afaik, these days, the vast majority of the software developers on Earth arenâ€™t coding in assembly). There is a middle-ground, but it changes over time, due to skills, deadlines, priorities, and so forth.\nSoâ€¦ I hate to break it to you dear readerâ€¦ but contrary to the popular beliefğŸŒ that â€œitâ€™s always better to have a close-to-the-metalğŸ”§ implementation that you can gradually customize and tune accordingly to your very needsâ€ (and illustrated in articles like this one, or that one), it seems that well itâ€™s not always that â€œstraightforwardâ€ to figure out who or more exactly what is actually doing the heavy lifting.\nMaintaining our messaging implementationâœ‰ï¸ with the official RabbitMQ .NET client with all its caveats had a cost and it became increasingly expensive to keep up with all the new features and the ones that are going to be released.\nThe valueğŸ’° we bring to our project is not measured by the time we spent on tweaking the official RabbitMQ .NET client by doing the heavy lifting ourselves but rather by providing business-value to our stakeholders and end-users.\nâ€œItâ€™s all your f*cking fault!â€ or â€œAmateur-hour, Admit it! You just made a monumental mistake!â€ ğŸ™‡â€â™€ï¸ It could be very tempting to draw this kind of conclusion, but the truth is â€œnopeâ€, nawt really, sorry pal, I do mean it.\nFun facts:\n We actually even had a branch with the S3 solution ready to be merged a few months agoğŸ“…, but we didnâ€™t know business priorities would change that much over time and the priority was given to other more important topicsğŸ¤‘. We started with EasyNetQ back in the day, but the configuration system wasnâ€™t too appealing and we were afraid that we would have been stuck with this lib at some point, i.e. a situation similar to a vendor lock-inğŸ”’.  The CheesyğŸ§€-CornyğŸ¿ MomentâŒ› (also known as The Emotional Natalie MomentğŸ¤¸â€â™€ï¸, but letâ€™s just pretend itâ€™s actually wholesomeğŸ§¸).\nYou can always regret that you havenâ€™t done enough. But here are my cheap 2 centsğŸ‘›: itâ€™s pointless. You canâ€™t know everything in advance and making wild guesses about the future doesnâ€™t seem like a reasonable option either. You learn what you can learn from something that didnâ€™t pan out as good as you expected it to be, but it doesnâ€™t mean that the decisions you made back then were all just plain wrong.\nYour decision process is just as contextual as the constraints involved when you were making those very same decisions at a given timeğŸ“†. It is unproductive to place the blame on a context.\nI would even go as far as to say that blaming is probably the thing we should all probably refrain ourselves from doing. Instead we would all be much better off focusing on finding solutions and actionable tasks to solve our problems rather than just getting pissed at the circumstances and going round in circles.\n The devilğŸ˜ˆ is in the details.\n   ","wordCount":"2459","inLanguage":"en","image":"https://natalie-o-perret.github.io/images/gallery/2-2021-02-15-post-mortem-how-to-handle-big-files-with-rabbitmq-and-postgresql.jpg","datePublished":"2021-02-15T00:00:00Z","dateModified":"2021-02-15T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://natalie-o-perret.github.io/posts/2-2021-02-15-post-mortem-how-to-handle-big-files-with-rabbitmq-and-postgresql/"},"publisher":{"@type":"Organization","name":"ğŸˆNatalie PerretğŸ«","logo":{"@type":"ImageObject","url":"https://natalie-o-perret.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://natalie-o-perret.github.io/ accesskey=h title="ğŸˆNatalie PerretğŸ« (Alt + H)">ğŸˆNatalie PerretğŸ«</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://natalie-o-perret.github.io/about title=AboutğŸ†”><span>AboutğŸ†”</span></a></li><li><a href=https://natalie-o-perret.github.io/search/ title=SearchğŸ”><span>SearchğŸ”</span></a></li><li><a href=https://natalie-o-perret.github.io/tags/ title=TagsğŸ·ï¸><span>TagsğŸ·ï¸</span></a></li><li><a href=https://natalie-o-perret.github.io/archives/ title=ArchivesğŸ—ƒï¸><span>ArchivesğŸ—ƒï¸</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://natalie-o-perret.github.io/>Home</a>&nbsp;Â»&nbsp;<a href=https://natalie-o-perret.github.io/posts/>Posts</a></div><h1 class=post-title>Post-mortemâœ¨ğŸ’€: How To Handle Big Files With RabbitMQğŸ‡ and PostgreSQLğŸ˜?</h1><div class=post-description>I love it when a plan comes together, but there are times it just doesn'tğŸª–.</div><div class=post-meta><span title="2021-02-15 00:00:00 +0000 UTC">February 15, 2021</span>&nbsp;Â·&nbsp;12 min</div></header><figure class=entry-cover><img loading=lazy src=https://natalie-o-perret.github.io/images/gallery/2-2021-02-15-post-mortem-how-to-handle-big-files-with-rabbitmq-and-postgresql.jpg alt="I can clearly see the elephantğŸ‡¹ğŸ‡­ğŸ˜, but where is Nivens McTwispğŸ°? "><p>I can clearly see the elephantğŸ‡¹ğŸ‡­ğŸ˜, but where is Nivens McTwispğŸ°?</p></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#tldr- aria-label="TL;DR â±ï¸">TL;DR â±ï¸</a></li><li><a href=#context- aria-label="Context ğŸ–¼ï¸">Context ğŸ–¼ï¸</a><ul><li><a href=#at-first-it-was-just-a-rabbitmq-thingy- aria-label="At first, it was just a RabbitMQ thingy&amp;hellip; ğŸ‡">At first, it was just a RabbitMQ thingy&mldr; ğŸ‡</a></li><li><a href=#the-process- aria-label="The Process âš™ï¸">The Process âš™ï¸</a></li><li><a href=#oopsie-seems-like-postgresql--is-also-failing aria-label="Oopsie&amp;hellip; seems like PostgreSQL ğŸ˜ is also failing!">Oopsie&mldr; seems like PostgreSQL ğŸ˜ is also failing!</a></li><li><a href=#rabbitmq--multithreading--a-love-story--nope aria-label="RabbitMQğŸ‡ + Multithreading ğŸ§µ: A Love Story ğŸ’&amp;hellip; NopeâŒ">RabbitMQğŸ‡ + Multithreading ğŸ§µ: A Love Story ğŸ’&mldr; NopeâŒ</a></li><li><a href=#it-works-but-not-on-my-machine-the-usual-natalie- aria-label="&amp;ldquo;It works&amp;hellip; but not on my machine!&amp;rdquo; (the usual Natalie ğŸ’»ğŸ™‹â€â™€ï¸)">&ldquo;It works&mldr; but not on my machine!&rdquo; (the usual Natalie ğŸ’»ğŸ™‹â€â™€ï¸)</a></li><li><a href=#hey-cap-looks-like-its-related-to-your-hardware- aria-label="&amp;ldquo;Hey Cap&amp;rsquo;, looks like it&amp;rsquo;s related to your hardware&amp;rdquo; ğŸ’½ğŸ‘©â€âœˆï¸">&ldquo;Hey Cap&rsquo;, looks like it&rsquo;s related to your hardware&rdquo; ğŸ’½ğŸ‘©â€âœˆï¸</a></li><li><a href=#better-parallelism-an-attempt- aria-label="Better Parallelism, an attempt â†—ï¸ğŸ§µ">Better Parallelism, an attempt â†—ï¸ğŸ§µ</a></li><li><a href=#btw-if-its-really-just-a-timeout-problem-cant-you-just-increase-the-value-of-the-so-called-timeout- aria-label="&amp;ldquo;Btw, if it&amp;rsquo;s really just a timeout problem, can&amp;rsquo;t you just increase the value of the so-called timeout?&amp;rdquo; â†—ï¸â³">&ldquo;Btw, if it&rsquo;s really just a timeout problem, can&rsquo;t you just increase the value of the so-called timeout?&rdquo; â†—ï¸â³</a></li><li><a href=#big-file-you-are-beautiful- aria-label="Big File (You Are Beautiful!) ğŸŒˆğŸ’¾">Big File (You Are Beautiful!) ğŸŒˆğŸ’¾</a></li></ul></li><li><a href=#solution- aria-label="Solution ğŸŒŸ">Solution ğŸŒŸ</a><ul><li><a href=#a-corporateie-on-premise-s3- aria-label="(&amp;ldquo;a&amp;rdquo; Corporate[i.e. on-premise]) S3 â˜ï¸">(&ldquo;a&rdquo; Corporate[i.e. on-premise]) S3 â˜ï¸</a></li><li><a href=#easynetq- aria-label="EasyNetQ ğŸ°âŒ¨ï¸">EasyNetQ ğŸ°âŒ¨ï¸</a></li></ul></li><li><a href=#its-all-your-fcking-fault-or-amateur-hour-admit-it-you-just-made-a-monumental-mistake- aria-label="&amp;ldquo;It&amp;rsquo;s all your f*cking fault!&amp;rdquo; or &amp;ldquo;Amateur-hour, Admit it! You just made a monumental mistake!&amp;rdquo; ğŸ™‡â€â™€ï¸">&ldquo;It&rsquo;s all your f*cking fault!&rdquo; or &ldquo;Amateur-hour, Admit it! You just made a monumental mistake!&rdquo; ğŸ™‡â€â™€ï¸</a></li></ul></div></details></div><div class=post-content><h1 id=tldr->TL;DR â±ï¸<a hidden class=anchor aria-hidden=true href=#tldr->#</a></h1><p>Long story short: 90%-out-of-the-blue chance that you just don&rsquo;t.</p><p>If you want more details about our story, then feel free to keep reading ğŸ‘“â¬‡ï¸.</p><h1 id=context->Context ğŸ–¼ï¸<a hidden class=anchor aria-hidden=true href=#context->#</a></h1><p>A not-so-long-whileğŸ¦– agoğŸ¦• we had some alertsğŸ“ŸğŸ”” in our dedicated Slack ChannelğŸ’¬, triggered every now and then when a particular HangFire job was running:</p><pre tabindex=0><code>&#34;XXXXXXX DataLoader&#34;
&#34;Production&#34;
Error
2021-01-22 09:04
SpanId: &#34;xxxxxxxxxxxxx&#34;
TraceId: &#34;xxxxxxxxxxxxx&#34;
An unhandled exception occurred during the Hangfire job.
Depth 0: System.AggregateException
One or more errors occurred. (The operation has timed out.)
Depth 1: System.TimeoutException
The operation has timed out.
</code></pre><h2 id=at-first-it-was-just-a-rabbitmq-thingy->At first, it was just a RabbitMQ thingy&mldr; ğŸ‡<a hidden class=anchor aria-hidden=true href=#at-first-it-was-just-a-rabbitmq-thingy->#</a></h2><p>We then looked at our logs in KibanağŸ”, just to find out that there was actually an issue related to opening a RabbitMQ ChannelğŸ“¡:</p><pre tabindex=0><code>System.AggregateException
One or more errors occurred. (The operation has timed out.)
System.AggregateException: One or more errors occurred. (The operation has timed out.)
 ---&gt; System.TimeoutException: The operation has timed out.
   at RabbitMQ.Util.BlockingCell`1.WaitForValue(TimeSpan timeout)
   at RabbitMQ.Client.Impl.SimpleBlockingRpcContinuation.GetReply(TimeSpan timeout)
   at RabbitMQ.Client.Impl.ModelBase.ModelRpc(MethodBase method, ContentHeaderBase header, Byte[] body)
   at RabbitMQ.Client.Framing.Impl.Model._Private_ChannelOpen(String outOfBand)
   at RabbitMQ.Client.Framing.Impl.AutorecoveringConnection.CreateNonRecoveringModel()
   at RabbitMQ.Client.Framing.Impl.AutorecoveringConnection.CreateModel()
[...]
</code></pre><p>GooglingğŸ” aroundğŸ—ºï¸ didn&rsquo;t yield too many results at first, even if we found a bunch of (remotely) related issues on GitHubğŸ—ƒï¸:</p><ul><li><a href=https://github.com/rabbitmq/rabbitmq-dotnet-client/issues/945>Time out exception on CreateModel in high volume scenario</a></li><li><a href=https://github.com/rabbitmq/rabbitmq-dotnet-client/issues/959>Using blocking publisher confirms with concurrent publishers</a></li><li><a href=https://github.com/rabbitmq/rabbitmq-dotnet-client/issues/650>Opening a channel inside a consumer interface callback times out waiting for continuation</a></li><li><a href=https://github.com/rabbitmq/rabbitmq-dotnet-client/issues/310>Timeout exception when trying to declare a queue (or exchange)</a></li></ul><h2 id=the-process->The Process âš™ï¸<a hidden class=anchor aria-hidden=true href=#the-process->#</a></h2><p>Since there wasn&rsquo;t really a clear solution out of our prelimenary investigations, it was time to step back and see a slightly bigger picture about what the Hangfire job was doing overall:</p><ol><li>Request data from an APIğŸ’±</li><li>Create groupsğŸ˜ï¸ based on some predicates</li><li>Process the groups as commands in our PostgreSQL-basedğŸ˜ event store and then persistğŸ’¾ the newly decided/generated events</li><li>PublishğŸ’¾ the events to RabbitMQğŸ‡</li></ol><h2 id=oopsie-seems-like-postgresql--is-also-failing>Oopsie&mldr; seems like PostgreSQL ğŸ˜ is also failing!<a hidden class=anchor aria-hidden=true href=#oopsie-seems-like-postgresql--is-also-failing>#</a></h2><p>Truth to be toldğŸ§™â€â™€ï¸, there was also an issue occuring during the PostgreSQL persistence step as wellğŸ”:</p><pre tabindex=0><code>An unhandled exception has occurred while executing the request.
System.AggregateException: One or more errors occurred. (One or more errors occurred. (One or more errors occurred. (One or m
ore errors occurred. (Exception while reading from stream))))
 ---&gt; System.AggregateException: One or more errors occurred. (One or more errors occurred. (One or more errors occurred. (Ex
ception while reading from stream)))
 ---&gt; System.AggregateException: One or more errors occurred. (One or more errors occurred. (Exception while reading from str
eam))
 ---&gt; System.AggregateException: One or more errors occurred. (Exception while reading from stream)
 ---&gt; Npgsql.NpgsqlException (0x80004005): Exception while reading from stream
 ---&gt; System.TimeoutException: Timeout during reading attempt
</code></pre><h2 id=rabbitmq--multithreading--a-love-story--nope>RabbitMQğŸ‡ + Multithreading ğŸ§µ: A Love Story ğŸ’&mldr; NopeâŒ<a hidden class=anchor aria-hidden=true href=#rabbitmq--multithreading--a-love-story--nope>#</a></h2><p>Another pesty little detailğŸ¦ , is that we tried to speed upâ© the RabbitMQ publishing process using <a href=http://fsprojects.github.io/FSharp.Collections.ParallelSeq><code>PSeq</code></a> and the <a href=https://github.com/rabbitmq/rabbitmq-dotnet-client/blob/master/projects/RabbitMQ.Client/client/impl/BasicPublishBatch.cs#L38>PublishBatch API of the official RabbitMQ .NET client</a>.</p><p>The thing you see, is that during our first iterationğŸ§—â€â™€ï¸ when implementing this service (and more generally-speaking when we were implementing the RabbitMQ support in our codebase), we already have experienced issues while experimenting with <a href=https://github.com/rabbitmq/rabbitmq-dotnet-client/blob/master/projects/RabbitMQ.Client/client/api/IModel.cs/#L48><code>IModel</code></a> in a concurrent fashion (i.e. multithreading) which obviously turned out to be a rather infamously well-known concernğŸ‘©â€ğŸ¤. So much, that there is in fact, <a href=https://www.rabbitmq.com/dotnet-api-guide.html#concurrency-channel-sharing>a section of the official RabbitMQ dedicated about it</a>:</p><blockquote><p>As a rule of thumb, <code>IModel</code> instance usage by more than one thread simultaneously should be avoided. Application code should maintain a clear notion of thread ownership for <code>IModel</code> instances.</p></blockquote><p>So here is the catch, we were not using EasyNetQ, or any abstraction layer on top of <a href=https://github.com/rabbitmq/rabbitmq-dotnet-client>the official RabbitMQ .NET client</a>, and something like the management of a single instance of <code>IModel</code> per thread was suboptimal to put it mildly, i.e. we were creating a new <code>IModel</code> instance everytime we needed to send a batch of messages wich at some point started to create a bottleneck (i.e. several instantiations per threadğŸ§µ).</p><p>Tbf, it was already a source of strugglesğŸ‹ï¸â€â™€ï¸, actually we&rsquo;ve noticed that our implementation was much slowerğŸŒ at sending messages than the EasyNetQ abstraction&mldr; and one of the reasons was the way EasyNetQ achieved this one single <code>IModel</code> instance per thread policy, in essence the number of <code>IModel</code> instances is kept to a bare minimum. Some of the important building blocks are listed below:</p><ul><li><a href=https://github.com/EasyNetQ/EasyNetQ/blob/develop/Source/EasyNetQ/Internals/AsyncLock.cs><code>AsyncLock</code></a></li><li><a href=https://github.com/EasyNetQ/EasyNetQ/blob/521589682b76123b0c409086c5afe86f7659871b/Source/EasyNetQ/RabbitAdvancedBus.cs#L335><code>RabbitAdvancedBus</code></a></li><li><a href=https://github.com/EasyNetQ/EasyNetQ/blob/develop/Source/EasyNetQ/Producer/PersistentChannel.cs><code>PersistentChannel</code></a></li></ul><p>Anyway, my colleague <a href=https://www.linkedin.com/in/yazideboujlil/>Yazide Boujlil</a> managed to come up with the explanations below:</p><blockquote><p>For each client connection, we have a socket which is shared between the threads via a <a href=https://docs.microsoft.com/en-us/dotnet/api/system.threading.channels.channel><code>.NET Channel</code></a> that acts as some sort of buffer. Several threads can write to it, but only a single thread will read what is there and therefore will eventually write data to the relevant socket.</p><p>The RMQ channels (<code>IModel</code>) are merely the byproductsğŸ¤ of the RMQ connection. Each message which passes through the socket contains the ID of the channel to which it is attached. To declare a channel you need a small blocking RPC upon which we have experienced our annoying timeoutsâ°.</p><p>Now it turns out that the server can actually put connectionsğŸ”Œ that publish too quicklyğŸš… (compared to consumers) in flow control mode, i.e. aka on hold, like putting them on iceğŸ§Š, and block and unblock the connection to limit the flow of messagesğŸš§.</p><p>Now what is happening, in my opinion, is that we ended up in a situation where we overload both the server and the client. The server goes into a flow control mode which does not allow the client to empty its buffer and therefore any new channel creation is blocked until the cache is cleared. As there is a timeout on the channel creation, eventually the shit hit the fan.</p></blockquote><p>We naively thought that using the good oldğŸ‘µ <a href=https://docs.microsoft.com/en-us/dotnet/api/system.threading.threadlocal-1><code>ThreadLocal&lt;'T></code></a> was the simplest and easiest way to go to keep this one <code>IModel</code> instance per thread.</p><p>Anyhoo, we kept investigatingğŸ”¬ to tackle this <code>IModel</code> issue in a concurrent context, and found a few articles (two of the links below were written by <a href=https://twitter.com/mikehadlow>Mike Hadlow</a>, the author of the <a href=https://easynetq.com>EasyNetQ</a> library):</p><ul><li><a href=https://github.com/dotnet/runtime/issues/2382>Very high latency for GC when using (loads of) <code>ThreadLocal</code></a></li><li><a href=https://dzone.com/articles/easynetq-breaking-change>EasyNetQ: A Breaking Change, <code>IPublishChannel</code></a></li><li><a href=https://stackoverflow.com/questions/10432494/how-do-i-detect-when-a-client-thread-exits>How Do I Detect When a Client Thread Exits?</a></li></ul><p>The point made by MikeğŸ‘‡:</p><blockquote><p>Initially I&rsquo;d hoped to hide channels from EasyNetQ usersğŸ™ˆ. With subscriptions this makes sense - after the client creates a subscription, EasyNetQ looks after the channel and the subscription consuming thread. But publishing turned out to be more complex. Channels cannot be shared between threads, so EasyNetQ initially used a <code>ThreadLocal</code> channel for all publish callsâ˜ï¸. A new thread meant a new channelğŸŒ„.</p><p>This problem manifested itself with a nasty operational bug we suffered. We had a service which woke up on a timer, created some threads, and published messages on them. <strong>Although the threads ended, the channels didn&rsquo;t closeğŸ“­, and each timer intervalğŸ•°ï¸ added another few open channels</strong>.</p></blockquote><p>So ok&mldr; it seems that just relying on the vanilla edition of <code>ThreadLocal&lt;'T></code>ğŸ¨ might not do, mostly cause this concurrency primitive does not handle the exiting thread scenario.</p><p>Fair enough, we kept googlingğŸ” and found these two little gemsğŸ’ drafted by AyendeğŸ‘¨â€ğŸ«:</p><ul><li><a href=https://ayende.com/blog/189761-A/production-postmortem-the-slow-slowdown-of-large-systems>The slow slowdown of large systems</a></li><li><a href=https://ayende.com/blog/189793-A/the-design-and-implementation-of-a-better-threadlocal-t>The design and implementation of a better <code>ThreadLocal&lt;T></code></a></li></ul><p>As well this libraryğŸ“š:</p><ul><li><a href=https://github.com/ptupitsyn/UnmanagedThreadUtils>UnmanagedThreadUtils</a></li></ul><p>We started to draft our own implementation of <code>ThreadLocal&lt;'T></code> supporting the thread exiting scenario when carrying a <code>IDisposable</code> resource, a bit like what is described in <a href=https://stackoverflow.com/a/7670762/4636721>this SO answer</a>.</p><h2 id=it-works-but-not-on-my-machine-the-usual-natalie->&ldquo;It works&mldr; but not on my machine!&rdquo; (the usual Natalie ğŸ’»ğŸ™‹â€â™€ï¸)<a hidden class=anchor aria-hidden=true href=#it-works-but-not-on-my-machine-the-usual-natalie->#</a></h2><p>At this stage, we were fairly confident that we had a working solution to solve our initial problem. But spoiler alert: we did not and we were once again prooved all wrongğŸ™…â€â™€ï¸, once again. While we were reviewing our new solution before shipping it to our integration environment, we quickly realized that there was something off when using a sizable amount of data. In fact, I still kept having timeoutsâ° while my other colleagues did not. We were all testing using the same codebase and the same Docker configurationğŸ‹&mldr; so by all accounts we were supposed to get the same results and&mldr; and we were all wondering &ldquo;How is that even possible?&rdquo;</p><h2 id=hey-cap-looks-like-its-related-to-your-hardware->&ldquo;Hey Cap&rsquo;, looks like it&rsquo;s related to your hardware&rdquo; ğŸ’½ğŸ‘©â€âœˆï¸<a hidden class=anchor aria-hidden=true href=#hey-cap-looks-like-its-related-to-your-hardware->#</a></h2><p>Fair enough, yes, my laptopğŸ’» is infamously slow when compared to the machinesğŸ–¥ï¸ of my teammates.</p><p>It didn&rsquo;t take us too long to realize that given different pieces of hardware (RAM, CPU) accessed (i.e. limited) either thru a VM or a Docker ContainerğŸ³ mean they still can have vastly different performances. It&rsquo;s then easy to understand that the underlying hardware powering this or that bit of infra is likely to improve or worsen the capability to support a bigger number of concurrent writers. If your hardware falls short, it&rsquo;s very likely that you&rsquo;re going to have a lock-bottleneck at some point.</p><h2 id=better-parallelism-an-attempt->Better Parallelism, an attempt â†—ï¸ğŸ§µ<a hidden class=anchor aria-hidden=true href=#better-parallelism-an-attempt->#</a></h2><p>One way to tackle the overall concurrency per layer of infra was to adjust using the TPL <a href=https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/dataflow-task-parallel-library>DataFlow - TPL</a>. It goes without saying that different environment had different infra constraints.</p><h2 id=btw-if-its-really-just-a-timeout-problem-cant-you-just-increase-the-value-of-the-so-called-timeout->&ldquo;Btw, if it&rsquo;s really just a timeout problem, can&rsquo;t you just increase the value of the so-called timeout?&rdquo; â†—ï¸â³<a hidden class=anchor aria-hidden=true href=#btw-if-its-really-just-a-timeout-problem-cant-you-just-increase-the-value-of-the-so-called-timeout->#</a></h2><p>Yes and we did on multiple occasions. Also one more thing, it wasn&rsquo;t just about a Hangfire job, we also have an admin api so-to-speak to restart the job we mentioned early on and it was expected to run within 5 minutes (or as fast as possible). The thing is that it wasn&rsquo;t just a timeout thing, or even just about parallelism and what we already listed above, cause&mldr;</p><h2 id=big-file-you-are-beautiful->Big File (You Are Beautiful!) ğŸŒˆğŸ’¾<a hidden class=anchor aria-hidden=true href=#big-file-you-are-beautiful->#</a></h2><p>&mldr; basically here is the deal, we needed to juggled with all these intertwined bits of parameters:</p><ul><li>PostgreSQL: Timeout (we want that as fast as possible)â°</li><li>RabbitMQ: Timeout (same as above)â°</li><li>RabbitMQ: Single <code>IModel</code> per Thread policyğŸ‘®â€â™€ï¸</li><li>Maximum degree of parallelism per &ldquo;IO layer&rdquo; ğŸ”€</li><li>The respective bits of hardware / VM / Docker containers supporting a given service and relevant bits of infrastructure dependenciesğŸ’ª</li></ul><p>The overall problem looked like a Gordian knotğŸ§¶ until we realized that we could bypass it altogether with a different approach&mldr; when we started to a have closer look at&mldr; well&mldr; the filesğŸ’¾ and more precisely, their average size.</p><p>In retrospect, persisting &ldquo;relatively big files&rdquo; 100MB either to a JSONB columnğŸ§® or to RabbitMQ (tho for the RabbitMQ part there were first split based on some business conditions) wasn&rsquo;t really the best option available out there&mldr; performance-wiseğŸ¢.</p><h1 id=solution->Solution ğŸŒŸ<a hidden class=anchor aria-hidden=true href=#solution->#</a></h1><p>Given all the information above, it became crystal clearğŸ”® that the main hiccup was to persist files where they were not really supposed to be persisted&mldr; so we decided to use&mldr;</p><h2 id=a-corporateie-on-premise-s3->(&ldquo;a&rdquo; Corporate[i.e. on-premise]) S3 â˜ï¸<a hidden class=anchor aria-hidden=true href=#a-corporateie-on-premise-s3->#</a></h2><p>Our first and original &ldquo;sin"ğŸ› was purely architecturalğŸ“. Removing the file persistenceğŸ’¾ from PostgreSQL and RabbitMQ &ldquo;duties&rdquo; and hence keeping just a reference(i.e. ID) to the file in the S3 bucketğŸ’¿ did alleviate a lot the IO burden by several orders of magnitude.</p><p>What we have done is essentially delegatingâï¸ the infra burden to another service that is good at handling file persistence and &ldquo;voila"ğŸ·ğŸ¥–.</p><p>Note: I didn&rsquo;t mention it when I first drafted this article, but if you consider that several instances of the same service are running simulatenously and given that the even store is a very central building block in our architecture it makes sense to NOT burden it with long concurrent writes.</p><h2 id=easynetq->EasyNetQ ğŸ°âŒ¨ï¸<a hidden class=anchor aria-hidden=true href=#easynetq->#</a></h2><p>This issue (and the investigations we did around this issue) made us realize another problem. When we started to use RabbitMQ in our project we thought we would need a certain granularity hence the decision to pick the rather low-level RabbitMQ .NET official client&mldr;</p><p>We had this premise, because in our past experience with Entity FrameworkğŸ§°, the overly complex abstraction made us litterally miserableğŸ˜¿ and we were spending (i.e. wasting?) more time fightingâš”ï¸ the framework than benefiting from it (i.e. you deliver less business-value).</p><p>But keep in mind that the opposite is also true (i.e. afaik, these days, the vast majority of the software developers on Earth aren&rsquo;t coding in assembly). There is a middle-ground, but it changes over time, due to skills, deadlines, priorities, and so forth.</p><p>So&mldr; I hate to break it to you dear reader&mldr; but contrary to the popular beliefğŸŒ that &ldquo;it&rsquo;s always better to have a close-to-the-metalğŸ”§ implementation that you can gradually customize and tune accordingly to your very needs&rdquo; (and illustrated in articles like <a href=https://www.ouarzy.com/2020/12/27/dont-reinvent-the-wheel>this one</a>, or <a href=https://www.ouarzy.com/2019/09/29/writing-code-isnt-the-bottleneck>that one</a>), it seems that well it&rsquo;s not always that &ldquo;straightforward&rdquo; to figure out who or more exactly what is actually doing the heavy lifting.</p><p>Maintaining our messaging implementationâœ‰ï¸ with the official RabbitMQ .NET client with all its caveats had a cost and it became increasingly expensive to keep up with all the new features and the ones that are going to be released.</p><p>The valueğŸ’° we bring to our project is not measured by the time we spent on tweaking the official RabbitMQ .NET client by doing the heavy lifting ourselves but rather by providing business-value to our stakeholders and end-users.</p><h1 id=its-all-your-fcking-fault-or-amateur-hour-admit-it-you-just-made-a-monumental-mistake->&ldquo;It&rsquo;s all your f*cking fault!&rdquo; or &ldquo;Amateur-hour, Admit it! You just made a monumental mistake!&rdquo; ğŸ™‡â€â™€ï¸<a hidden class=anchor aria-hidden=true href=#its-all-your-fcking-fault-or-amateur-hour-admit-it-you-just-made-a-monumental-mistake->#</a></h1><p>It could be very tempting to draw this kind of conclusion, but the truth is &ldquo;nope&rdquo;, nawt really, sorry pal, I do mean it.</p><p>Fun facts:</p><ol><li>We actually even had a branch with the S3 solution ready to be merged a few months agoğŸ“…, but we didn&rsquo;t know business priorities would change that much over time and the priority was given to other more important topicsğŸ¤‘.</li><li>We started with EasyNetQ back in the day, but the configuration system wasn&rsquo;t too appealing and we were afraid that we would have been stuck with this lib at some point, i.e. a situation similar to a vendor lock-inğŸ”’.</li></ol><p><em>The CheesyğŸ§€-CornyğŸ¿ MomentâŒ› (also known as The Emotional Natalie MomentğŸ¤¸â€â™€ï¸, but let&rsquo;s just pretend it&rsquo;s actually wholesomeğŸ§¸).</em></p><p>You can always regret that you haven&rsquo;t done enough. But here are my cheap 2 centsğŸ‘›: it&rsquo;s pointless. You can&rsquo;t know everything in advance and making wild guesses about the future doesn&rsquo;t seem like a reasonable option either. <strong>You learn what you can learn from something that didn&rsquo;t pan out as good as you expected it to be, but it doesn&rsquo;t mean that the decisions you made back then were all just plain wrong</strong>.</p><p><strong>Your decision process is just as contextual as the constraints involved when you were making those very same decisions at a given timeğŸ“†. It is unproductive to place the blame on a context.</strong></p><p><strong>I would even go as far as to say that blaming is probably the thing we should all probably refrain ourselves from doing. Instead we would all be much better off focusing on finding solutions and actionable tasks to solve our problems rather than just getting pissed at the circumstances and going round in circles.</strong></p><blockquote><p>The devilğŸ˜ˆ is in the details.</p></blockquote><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube-nocookie.com/embed/NsUFBm1uENs style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://natalie-o-perret.github.io/tags/coding/>coding</a></li><li><a href=https://natalie-o-perret.github.io/tags/work/>work</a></li><li><a href=https://natalie-o-perret.github.io/tags/interview/>interview</a></li></ul><nav class=paginav><a class=next href=https://natalie-o-perret.github.io/posts/1-2020-08-14-challenge-accepted/><span class=title>Next Â»</span><br><span>Challenge Accepted âœ…</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Post-mortemâœ¨ğŸ’€: How To Handle Big Files With RabbitMQğŸ‡ and PostgreSQLğŸ˜? on twitter" href="https://twitter.com/intent/tweet/?text=Post-mortem%e2%9c%a8%f0%9f%92%80%3a%20How%20To%20Handle%20Big%20Files%20With%20RabbitMQ%f0%9f%90%87%20and%20PostgreSQL%f0%9f%90%98%3f&url=https%3a%2f%2fnatalie-o-perret.github.io%2fposts%2f2-2021-02-15-post-mortem-how-to-handle-big-files-with-rabbitmq-and-postgresql%2f&hashtags=coding%2cwork%2cinterview"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Post-mortemâœ¨ğŸ’€: How To Handle Big Files With RabbitMQğŸ‡ and PostgreSQLğŸ˜? on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fnatalie-o-perret.github.io%2fposts%2f2-2021-02-15-post-mortem-how-to-handle-big-files-with-rabbitmq-and-postgresql%2f&title=Post-mortem%e2%9c%a8%f0%9f%92%80%3a%20How%20To%20Handle%20Big%20Files%20With%20RabbitMQ%f0%9f%90%87%20and%20PostgreSQL%f0%9f%90%98%3f&summary=Post-mortem%e2%9c%a8%f0%9f%92%80%3a%20How%20To%20Handle%20Big%20Files%20With%20RabbitMQ%f0%9f%90%87%20and%20PostgreSQL%f0%9f%90%98%3f&source=https%3a%2f%2fnatalie-o-perret.github.io%2fposts%2f2-2021-02-15-post-mortem-how-to-handle-big-files-with-rabbitmq-and-postgresql%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Post-mortemâœ¨ğŸ’€: How To Handle Big Files With RabbitMQğŸ‡ and PostgreSQLğŸ˜? on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fnatalie-o-perret.github.io%2fposts%2f2-2021-02-15-post-mortem-how-to-handle-big-files-with-rabbitmq-and-postgresql%2f&title=Post-mortem%e2%9c%a8%f0%9f%92%80%3a%20How%20To%20Handle%20Big%20Files%20With%20RabbitMQ%f0%9f%90%87%20and%20PostgreSQL%f0%9f%90%98%3f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Post-mortemâœ¨ğŸ’€: How To Handle Big Files With RabbitMQğŸ‡ and PostgreSQLğŸ˜? on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fnatalie-o-perret.github.io%2fposts%2f2-2021-02-15-post-mortem-how-to-handle-big-files-with-rabbitmq-and-postgresql%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Post-mortemâœ¨ğŸ’€: How To Handle Big Files With RabbitMQğŸ‡ and PostgreSQLğŸ˜? on whatsapp" href="https://api.whatsapp.com/send?text=Post-mortem%e2%9c%a8%f0%9f%92%80%3a%20How%20To%20Handle%20Big%20Files%20With%20RabbitMQ%f0%9f%90%87%20and%20PostgreSQL%f0%9f%90%98%3f%20-%20https%3a%2f%2fnatalie-o-perret.github.io%2fposts%2f2-2021-02-15-post-mortem-how-to-handle-big-files-with-rabbitmq-and-postgresql%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Post-mortemâœ¨ğŸ’€: How To Handle Big Files With RabbitMQğŸ‡ and PostgreSQLğŸ˜? on telegram" href="https://telegram.me/share/url?text=Post-mortem%e2%9c%a8%f0%9f%92%80%3a%20How%20To%20Handle%20Big%20Files%20With%20RabbitMQ%f0%9f%90%87%20and%20PostgreSQL%f0%9f%90%98%3f&url=https%3a%2f%2fnatalie-o-perret.github.io%2fposts%2f2-2021-02-15-post-mortem-how-to-handle-big-files-with-rabbitmq-and-postgresql%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://natalie-o-perret.github.io/>ğŸˆNatalie PerretğŸ«</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.classList.add("transition-delay"),document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerHTML="copy";function s(){e.innerHTML="copied!",setTimeout(()=>{e.innerHTML="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script></body></html>